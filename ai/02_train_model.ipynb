{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dca113-8ddc-4141-a143-4732b40d8a0e",
   "metadata": {},
   "source": [
    "# 2. Word embedding model training\n",
    "\n",
    "Following approach in [tutorial](https://rare-technologies.com/word2vec-tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2bfd74-94e0-454d-8778-2f0677fbd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5fc73-f795-4a51-8105-ce1cd20c90f5",
   "metadata": {},
   "source": [
    "## 2.1 Preprocessing\n",
    "Preprocessing involves Textblob's tokenising, lemmatisation, lower case, matching to `(((?![\\d])\\w)+)` regex (as per gensim, to remove trailing punctuation), stopword removal (see `api.preprocess.document_to_tokens`), length filter. \n",
    "\n",
    "Null value removal isn't necessary because tokenisation sorts everything out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf186243-160e-473c-ab57-0aa17ed7d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 10:21:02,633 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2022-10-04 10:21:02,634 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2022-10-04 10:21:02,635 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2022-10-04T10:21:02.635001', 'gensim': '4.2.0', 'python': '3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from api.preprocess import TrainingCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d315223a-af77-40a2-9aa5-7ad5fb60fa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leonard', 'shenoff', 'randle', 'bear', 'february', 'major', 'league', 'baseball', 'player', 'he', 'first', 'pick', 'washington', 'senator', 'secondary', 'phase', 'june', 'major', 'league', 'baseball', 'draft', 'tenth', 'overall']\n",
      "['philippe', 'adnot', 'bear', 'august', 'rhèges', 'member', 'senate', 'france', 'he', 'first', 'elect', 'represent', 'aube', 'department', 'farmer', 'profession', 'he', 'serve', 'independent', 'serve', 'head', 'general', 'council', 'aube', 'he', 'elect', 'represent', 'canton', 'méry', 'he', 'senate', 'first', 'round', 'avoid', 'need', 'run', 'vote', 'contribute', 'creation', 'university', 'technology', 'troyes', 'he', 'first', 'vice', 'president', 'university', 'board', 'he', 'currently', 'president', 'he', 'member', 'senate', 'committee', 'law', 'relate', 'freedom', 'responsibility', 'university', 'he', 'serve', 'delegate', 'administrative', 'meeting', 'senator', 'list', 'group', 'he', 'decorate', 'chevalier', 'ordre', 'national', 'mérite', 'agricole']\n",
      "['miroslav', 'popov', 'bear', 'june', 'dvůr', 'králové', 'nad', 'labem', 'czech', 'grand', 'prix', 'motorcycle', 'racer', 'he', 'currently', 'race', 'fim', 'cev', 'moto', 'championship', 'montaze', 'broz', 'race', 'team', 'aboard', 'suter']\n",
      "['john', 'jack', 'reynolds', 'february', 'march', 'footballer', 'play', 'west', 'bromwich', 'albion', 'aston', 'villa', 'celtic', 'international', 'he', 'play', 'time', 'ireland', 'emerge', 'he', 'actually', 'english', 'he', 'subsequently', 'play', 'time', 'england', 'he', 'player', 'bar', 'goal', 'score', 'england', 'player', 'play', 'ireland', 'england', 'he', 'win', 'fa', 'cup', 'west', 'bromwich', 'albion', 'prominent', 'member', 'successful', 'aston', 'villa', 'team', 'win', 'english', 'league', 'title', 'fa', 'cup', 'include', 'double', 'reynolds', 'note', 'highly', 'competitive', 'player', 'remarkable', 'ball', 'skill', 'exceptionally', 'brilliant', 'footwork', 'he', 'regard', 'great', 'footballer', 'highest', 'paid', 'player', 'his', 'generation', 'he', 'gain', 'reputation', 'drinking', 'womanising', 'result', 'money', 'he', 'earn', 'disappeared', 'he', 'father', 'illegitimate', 'child', 'he', 'appear', 'court', 'non', 'child', 'maintenance', 'his', 'heavy', 'drinking', 'blight', 'his', 'career', 'brief', 'spell', 'celtic', 'southampton', 'he', 'semi', 'journeyman', 'end', 'his', 'life', 'he', 'work', 'miner', 'sheffield', 'he', 'die', 'boarding', 'house', 'age', 'reynolds', 'his', 'career', 'subject', 'lecture', 'include', 'entitle', 'play', 'football', 'win', 'friend', 'die', 'young', 'life', 'john', 'reynolds', 'dr', 'neal', 'garnham', 'university', 'ulster']\n",
      "['william', 'ato', 'ankrah', 'bear', 'july', 'better', 'know', 'his', 'stage', 'akoo', 'nana', 'hiplife', 'musician', 'ghana', 'he', 'large', 'impact', 'africa', 'hiplife', 'scene', 'his', 'authentic', 'sounding', 'music', 'captivating', 'stage', 'craft']\n",
      "['teoctist', 'bear', 'toader', 'arăpașu', 'february', 'july', 'patriarch', 'romanian', 'orthodox', 'church', 'teoctist', 'serve', 'his', 'first', 'year', 'patriarch', 'romanian', 'communist', 'regime', 'accuse', 'collaboration', 'he', 'offer', 'his', 'resignation', 'romanian', 'revolution', 'soon', 'restore', 'office', 'serve', 'year', 'promoter', 'ecumenical', 'dialogue', 'patriarch', 'teoctist', 'invite', 'pope', 'john', 'paul', 'ii', 'visit', 'romania', 'first', 'visit', 'pope', 'predominantly', 'eastern', 'orthodox', 'country', 'east', 'schism']\n"
     ]
    }
   ],
   "source": [
    "corpus = TrainingCorpus(\"dataset_wikibios_merged\", tokenize_before_training=True)\n",
    "for i,sentence in enumerate(corpus):\n",
    "    print(sentence)\n",
    "    if i==5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e81f83-a557-4277-8bcb-f46036b74846",
   "metadata": {},
   "source": [
    "## 2.2 Train single embedding model\n",
    "If `tokenize_before_training==True`, creating the corpus will take some time tokenizing corpus but will save lots of time in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c13d6b9-a782-4da9-a5bc-6dab88a22bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55b2fb-c362-4ec8-bc9a-5973c3451c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TrainingCorpus(\"dataset_wikibios_merged\", tokenize_before_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7918ed1-389b-4000-a830-170a53be4b5d",
   "metadata": {},
   "source": [
    "Default epochs is 5, training takes ~ 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096a6f2-a70a-4dc6-a289-e90a71f112fb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=corpus, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3626ffd-814e-413a-9ac4-8dd413f1807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/dataset_wikibios_merged.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d7686-3b0d-4cc7-9ac5-e3c068f982f4",
   "metadata": {},
   "source": [
    "## 2.3 Train embedding models for all datasets (for ensemble model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816d1e0-c9b5-4b59-b94b-6e4277435c43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for corpus in [\"dataset_bug_stereotype\", \"dataset_bug\", \"dataset_doughman\", \"dataset_doughman_stereotype\"]:\n",
    "    print(\"########\", corpus, \"#######\")\n",
    "    model = Word2Vec(sentences=TrainingCorpus(corpus, tokenize_before_training=True), workers=4)\n",
    "    model.save(f\"models/{corpus}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d503-e6b4-4205-8ad7-c1e81b52f640",
   "metadata": {},
   "source": [
    "## 2.3 Demo scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c43723-4e43-4d4f-8128-59a2d843785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.gender_bias import GenderBiasScorer, percentage_bias, biased_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf416d0-f793-4167-821c-22c4e61d2423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 10:21:27,018 : INFO : loading Word2Vec object from models/dataset_wikibios_merged.pt\n",
      "2022-10-04 10:21:27,076 : INFO : loading wv recursively from models/dataset_wikibios_merged.pt.wv.* with mmap=None\n",
      "2022-10-04 10:21:27,077 : INFO : loading vectors from models/dataset_wikibios_merged.pt.wv.vectors.npy with mmap=None\n",
      "2022-10-04 10:21:27,125 : INFO : loading syn1neg from models/dataset_wikibios_merged.pt.syn1neg.npy with mmap=None\n",
      "2022-10-04 10:21:27,157 : INFO : setting ignored attribute cum_table to None\n",
      "2022-10-04 10:21:28,003 : INFO : Word2Vec lifecycle event {'fname': 'models/dataset_wikibios_merged.pt', 'datetime': '2022-10-04T10:21:28.003207', 'gensim': '4.2.0', 'python': '3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "wv = Word2Vec.load(\"models/dataset_wikibios_merged.pt\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5bfd5d-23db-48ba-9a5b-273c16642e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = GenderBiasScorer(wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c43b5-3c05-4313-a31b-93f94d19550d",
   "metadata": {},
   "source": [
    "Input document string and get percentage bias and list of biased words. This function will be referred to by `api.py`. Threshold will be tuned for each model in evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36db1ec8-c6cd-435b-a1df-40fc9cf1206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_document = \"My guess is she can afford to pay a nutritionist who limits her to a reasonable caloric intake and a personal trainer who keeps her on a workout plan.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c8940b-2753-468e-a7d8-c1d81591fa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does not exist in vocab:  caloric\n"
     ]
    }
   ],
   "source": [
    "tokens, scores = scorer.score_document(test_document, thresh=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8439f963-23c3-4fe0-b38b-b67c844044d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_bias(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e665f73c-128e-45bf-bccf-73d6049bdfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biased_m': ['reasonable'],\n",
       " 'biased_f': ['guess', 'she', 'nutritionist', 'her', 'her'],\n",
       " 'unbiased': ['afford',\n",
       "  'pay',\n",
       "  'limit',\n",
       "  'caloric',\n",
       "  'intake',\n",
       "  'personal',\n",
       "  'trainer',\n",
       "  'workout',\n",
       "  'plan']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_words(tokens, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb9b2d-010b-4f81-921d-4407ee29eab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
