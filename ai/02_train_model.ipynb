{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dca113-8ddc-4141-a143-4732b40d8a0e",
   "metadata": {},
   "source": [
    "# 2. Word embedding model training\n",
    "\n",
    "Following approach in [tutorial](https://rare-technologies.com/word2vec-tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2bfd74-94e0-454d-8778-2f0677fbd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5fc73-f795-4a51-8105-ce1cd20c90f5",
   "metadata": {},
   "source": [
    "Preprocessing involves tokenising (gensim uses `(((?![\\d])\\w)+)` regex), stopword removal (see below). \n",
    "\n",
    "No stemming/lemmatisation needed for now. Null value removal isn't necessary because regex sorts everything out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dd5e4-6c97-4e63-91a7-04e18bfdd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopword_tokens\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571ce83-bca6-4298-9d27-0d1d0245c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = \"\"\"\n",
    "a about above across after afterwards again against all almost alone along already also although always am among amongst an and another any anyhow anyone anything anyway anywhere are around as at back be\n",
    "became because become becomes becoming been before beforehand being beside besides between beyond both bottom but by call can\n",
    "cannot cant co con could couldnt cry de\n",
    "did didn do does doesn doing don done down due during\n",
    "each eight eg either eleven else elsewhere enough etc even ever every everyone everything everywhere except few fifteen\n",
    "fifty fill find for former formerly forty found four from front full further get give go\n",
    "had has hasnt have hence here hereafter hereby herein hereupon how however hundred i ie\n",
    "if in inc indeed into is it its itself keep last latter latterly least less ltd\n",
    "just\n",
    "kg km\n",
    "made make many may me meanwhile might mill mine more moreover most mostly move much must my myself name namely\n",
    "neither never nevertheless next nine no nobody none noone nor not nothing now nowhere of off\n",
    "often on once one only onto or other others otherwise our ours ourselves out over own part per\n",
    "perhaps please put rather re\n",
    "quite\n",
    "rather really regarding\n",
    "same say see seem seemed seeming seems several should show side since sincere six sixty so some somehow someone something sometime sometimes somewhere still such take ten\n",
    "than that the then thence there thereafter thereby therefore therein thereupon these third this those though three through throughout thru thus to together too top toward towards twelve twenty two un under\n",
    "until up unless upon us used using\n",
    "various very via\n",
    "was we well were what whatever when whence whenever where whereafter whereas whereby wherein whereupon wherever whether which while whither who whoever whole whom whose why will with within without would yet you\n",
    "your yours yourself yourselves\n",
    "\n",
    "lrb rrb lcb rcb lsb rsb\n",
    "\"\"\"\n",
    "STOPWORDS = frozenset(w for w in STOPWORDS.split() if w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6097e1-68ac-4870-a7ce-5ecab0c8b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingCorpus:\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('/Users/andrew.wang/Documents/academy/project/kainosRecruitmentApi-TeamA/ai/data/corpus/dataset_wikibios_merged.txt')\n",
    "        for line in open(corpus_path):\n",
    "            tokens = utils.simple_preprocess(line)\n",
    "            tokens = remove_stopword_tokens(tokens, stopwords=STOPWORDS)\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529286b-f72e-4ee2-825e-b434ee035afc",
   "metadata": {},
   "source": [
    "Test tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315223a-af77-40a2-9aa5-7ad5fb60fa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = TrainingCorpus()\n",
    "for i,sentence in enumerate(corpus):\n",
    "    print(sentence)\n",
    "    if i==5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e81f83-a557-4277-8bcb-f46036b74846",
   "metadata": {},
   "source": [
    "Train embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13d6b9-a782-4da9-a5bc-6dab88a22bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55b2fb-c362-4ec8-bc9a-5973c3451c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TrainingCorpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7918ed1-389b-4000-a830-170a53be4b5d",
   "metadata": {},
   "source": [
    "Default epochs is 5, this takes ~ 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096a6f2-a70a-4dc6-a289-e90a71f112fb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=corpus, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3626ffd-814e-413a-9ac4-8dd413f1807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/word2vec_wikibios_merged.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d503-e6b4-4205-8ad7-c1e81b52f640",
   "metadata": {},
   "source": [
    "Simple testing. Load model and check word vocab works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf416d0-f793-4167-821c-22c4e61d2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"models/word2vec_wikibios_merged.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f926d-09b7-46fe-a29b-57446a58b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"man\", \"male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5304f5a-85ea-4216-97a2-f53733e81a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv[\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e861f9-89ea-4aff-8027-40aa8bbdae15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
